{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aenc_faces.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedhere/UInotebooks/blob/master/imgPorcessingABC/aenc_faces_instuctions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGod4GR2FMSH"
      },
      "source": [
        "author FBB for ETHICS OF DS 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0g7Y7l95Vo7"
      },
      "source": [
        "This exercise is designed to think about bias in facial recognition software. \n",
        "To better understand how mathematical models can be biased, you will create a model that can increase the resolution of the image and try to identify in which cases the model underperforms and why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKP3gIx3EN7_"
      },
      "source": [
        "# Autoencoder notebook \n",
        "create superresolution portraits from low resolution black and white images:\n",
        "- load a patch of images and lower the resolution\n",
        "- build an autoencoder with a bottleneck layer much smaller thn the number of pixels in an image\n",
        "- pass the lower resolution images as imput and the higher resolution images as output\n",
        "- ask the encoder to predict (generate) high resolution images from low resolution ones\n",
        "- test it on a headshot of yourself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS9BF8xoAaBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bb62c4-06b5-4f02-886e-28047ce2f2dd"
      },
      "source": [
        "# this will connect this notebook to your google drive. \n",
        "# You will need to approve the mounting point by choosing the account and \n",
        "# getting a code to be paster into this cell \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka6VAkT6DZHM"
      },
      "source": [
        "# this loads the keras library for deep learning\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense#, Dropout, Flatten\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adamax\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJyom6NZbaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5590d8-318b-4add-96e3-4152124ddc41"
      },
      "source": [
        "# this loads other functions\n",
        "import glob # to look for date in the folders on the drive\n",
        "import h5py # to save DL models after training and read saved models\n",
        "from PIL import Image # to interact with images\n",
        "import numpy as np # for mathematical operations in python\n",
        "import pylab as pl # to make plots\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJwQjk5zHsko"
      },
      "source": [
        "cd /content/gdrive/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXYsPCCiLkSk"
      },
      "source": [
        "you can choose a different destination than the one below, but if you do then you need to download the data. make sure you uncomment the ```wget``` line of code below and the ones that follow as appropriate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIcrN-B8Hi-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934b99fc-b2ce-4ef9-faf0-3bc4c01d1cf3"
      },
      "source": [
        "cd Shareddrives/MLTSA2020/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/Shareddrives/MLTSA2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3tUAvyNyaFQ",
        "outputId": "ea85af9e-979e-415a-8c49-d4f713cda354"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/Shareddrives/MLTSA2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNMZ_IPRKjJ5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F56R_CzCZfpu"
      },
      "source": [
        "# load head shots from original data and save as numpy array - if you want you can skip to the \"Read in data\" section\n",
        "faces95.zip is a compressed folder with headshots. It was removed from the internet after the \"Obama Whitening Debackle\". The code that follow was the original code to grab the data.  I have saved it and put it in a share drive that you should have access too. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRV0Y1k3I5F_"
      },
      "source": [
        "##DO NOT RUN:\n",
        "## this code no longer works cause the endpoint was removed\n",
        "#!wget https://cswww.essex.ac.uk/mv/allfaces/faces95.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2-EXkwUGVlA"
      },
      "source": [
        "##DO NOT RUN:\n",
        "## the file is already unzipped in the shared drive so you do not need to run this\n",
        "#!unzip faces95\\ \\(1\\).zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PBLU_0kGVgW"
      },
      "source": [
        "## I saved the processed file but if you want you can uncomment the cells below to redo it\n",
        "!ls faces95/*/*jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H86CuGTpGVap"
      },
      "source": [
        "## there are 1400 images so this is slow\n",
        "flist = glob.glob(\"faces95/*/*jpg\")\n",
        "flist.remove([f for f in flist if \"prima\" in f ][0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFZGDvy7GVXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc5b6d2-1f08-4357-a18b-a8f8cb3a1f26"
      },
      "source": [
        "N = len(flist)\n",
        "N"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1440"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEnoBy00GVM4"
      },
      "source": [
        "## this saves the data into a numpy array\n",
        "im = Image.open(flist[0])\n",
        "np_im = numpy.array(im)[:,:,:3].astype(float) / 255 #normalize the images so that they are 0-1\n",
        "pl.imshow(np_im)\n",
        "## I am going to need only a subset of the image: the center part where the head is\n",
        "\n",
        "np_im[25:165:2,25:165:2,:1].shape, np.prod(np_im.shape[1:]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRO9HLyPKxQo"
      },
      "source": [
        "## skip and read the saved version if you have saved it (after the first time you run this cell)\n",
        "imgs_orig = np.zeros((N, 70, 70, 1))\n",
        "for i,f in enumerate(flist):\n",
        "   if \"prima\" in f: continue\n",
        "   if not i%50: print(i)\n",
        "\n",
        "   im = Image.open(f)\n",
        "   np_im = numpy.array(im)[:,:,:3].astype(float) / 255 \n",
        "   # here I collect the certain portion of each image \n",
        "   # from pixel 25 to 165 on the x and y axis (25:165)\n",
        "   # and subsampling by a factor 2 (25:165:2)\n",
        "   # and I am only choosing 1 color layer: [...,:1]: the R in RGB layers\n",
        "   imgs_orig[i] = numpy.array(im)[25:165:2,25:165:2,:1].astype(float) / 255 \n",
        "#np.save(\"faces2.npy\", imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBPDLDqiGVWR"
      },
      "source": [
        "\n",
        "## read in data\n",
        "\n",
        "I saved the data in a numpy array: this way you can read it in more quickly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtdcbAa17cz9"
      },
      "source": [
        "#imgs_orig = np.load(\"faces2.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awujuib1Q8iD"
      },
      "source": [
        "print(\"\"\"There are {} images \n",
        "each {}x{} pixels and {} color channels\"\"\".format(*imgs_orig.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_xTnzagSnUQ"
      },
      "source": [
        "# create input-output pairs\n",
        "we want to create a model that can guess how a high resolution version of a low resolution headshot would look. We need to give it examples of low-res--high-res pairs. To do that we artificially lower the resolution of some images.\n",
        "\n",
        "## make a copy of the original before you lower the resolution#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1T-YpWvJPLF"
      },
      "source": [
        "#imgs orig is the full resolution image\n",
        "imgs = imgs_orig.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcqaIVO_JVQU"
      },
      "source": [
        "# this creates a lower the resolution version of the image: reads every other pixel\n",
        "imgs = imgs[:,::2,::2]\n",
        "imgs[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_VfqyxuKxIK"
      },
      "source": [
        "print(\"\"\"There {} low resolution images are \n",
        "each {}x{} pixels and {} color channels\"\"\".format(*imgs.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25GNF4TmKw-5"
      },
      "source": [
        "print(\"The number of pixels in each image is {}\".format(np.prod(imgs[0].shape)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuzhtLfG8RWz"
      },
      "source": [
        "## generate a train and test set\n",
        "The target variable will be a full resolution image set and the low input the lower resolution one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHEvInUNR1-s"
      },
      "source": [
        "An autoencoder is traditionally trained to learn how to reproduce itself: input=target\n",
        "\n",
        "We want to create a model that can increase the resolution of images: we will give the low resolution images as input and the high resolution image counterpart as target. Hovering over the function you can see what arguments it takes:\n",
        "\n",
        "```train_test_split(input, target, test_size, random_state)```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD5Tq_CTGVDc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_tr,  X_te, y_tr, y_te = train_test_split(# pass the input and target: the low res and the high res set\n",
        "                                             test_size = .05, random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH7G4XoNKw11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02711842-e4d6-4f59-ef2b-823bf18d9442"
      },
      "source": [
        "X_tr.shape, X_te.shape, y_tr.shape, y_te.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1368, 35, 35, 1), (72, 35, 35, 1), (1368, 70, 70, 1), (72, 70, 70, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV2Ej-TyVOII"
      },
      "source": [
        "ax = pl.figure(figsize=(10,5)).subplots(1,2)\n",
        "ax[0].imshow(np.squeeze(X_tr[0]), cmap=\"bone\");\n",
        "ax[1].imshow(np.squeeze(y_tr[0]), cmap=\"bone\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j7pMY1GOlku"
      },
      "source": [
        "ax = pl.figure(figsize=(10,5)).subplots(1,2)\n",
        "ax[0].imshow(np.squeeze(X_tr[1]), cmap=\"bone\");\n",
        "ax[1].imshow(np.squeeze(y_tr[1]), cmap=\"bone\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO-IKuTtGUIa"
      },
      "source": [
        "# this cell of code flattens the images: puts all pixels in a row\n",
        "# this is apprioriate if the neural network does not use convolutional layers\n",
        "X_tr = X_tr.reshape(len(X_tr), np.prod(X_tr.shape[1:]))\n",
        "X_te = X_te.reshape(len(X_te), np.prod(X_te.shape[1:]))\n",
        "y_tr = y_tr.reshape(len(y_tr), np.prod(y_tr.shape[1:]))\n",
        "y_te = y_te.reshape(len(y_te), np.prod(y_te.shape[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rBDMyCRPMKG"
      },
      "source": [
        "input_dim = X_tr[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2taigiAbUkf"
      },
      "source": [
        "# build an autoencoder model\n",
        "\n",
        "model.add([....] \n",
        "## add Dense layers - type Dense to see how to use the function to create a layer\n",
        "## remember that the network should have an hour glass shape\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAFXQiSPGVGE"
      },
      "source": [
        "# instantiate a sequential model: a deep neural network\n",
        "model = Sequential()\n",
        "\n",
        "#Encoder: reduces the size of the original image\n",
        "model.add(# add Dense layers - type Dense to see how to use the function to create a layer\n",
        "model.add(\n",
        "    \n",
        "# choose the optimizer and the learning rate\n",
        "opt = Adamax(\n",
        "    learning_rate=0.005)\n",
        "\n",
        "#compile the model choosing the loss and the metrics to keep track of\n",
        "model.compile(optimizer=opt, loss='mse',\n",
        "              metrics=['mae', 'acc'])\n",
        "#alternative options for optimizing optimizer=\"adadelta\", loss=\"kullback_leibler_divergence\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVcza_KHX0In"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2-USV-IaqeS"
      },
      "source": [
        "## train model OR you can skip and load the pretrained I saved for you!\n",
        "or to read in the saved model skip this cell, or skip the whole section and read a model from http://fbb.space/mltsa/imgreconstruct_10000.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdcuNPb1N_n7"
      },
      "source": [
        "# only use this if you are in your own folder\n",
        "# !mkdir facecheckpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeDmW09BNuSF"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LambdaCallback, EarlyStopping\n",
        "# this callback allows us to not to wast training time:\n",
        "# if the validation loss does not improve for N epochs in a row training stops\n",
        "patience = EarlyStopping(patience=20)\n",
        "# other callbacks that can be used to save intermediate training steps - only use if you are in your own folder\n",
        "# filepath = \"facecheckpoints/OneHotEncodedweights-improvement-{epoch:02d}-{loss:.4f}.hd5\" \n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, \n",
        "#                              save_best_only=True, mode='min')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi9L466xzwkH"
      },
      "source": [
        "# you can skip this and load the saved model\n",
        "history = model.fit(\n",
        "    #....\n",
        "    #pass the input and output data as first and second arguments\n",
        "    epochs=1000, #with the patience callback I can set lots of epochs \n",
        "                    validation_split=0.2,\n",
        "                    batch_size=150, verbose=1,\n",
        "                    callbacks=[patience])#, checkpoint])\n",
        "#model.save(\"facecheckpoints/imgreconstruct2021_100000.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2S-ygRvLDXU"
      },
      "source": [
        "pl.plot(np.array(history.history['loss']), label=\"loss\")\n",
        "pl.plot(np.array(history.history['val_loss']), label=\"validatoin loss\")\n",
        "pl.xlabel(\"epochs\")\n",
        "pl.yscale('log')\n",
        "pl.legend();\n",
        "#pl.xscale('log')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjloYmIK4SLE"
      },
      "source": [
        "## READ IN THE SAVED MODEL\n",
        "##!wget http://fbb.space/mltsa/imgreconstruct_10000.h5\n",
        "#model.load_weights(\"facecheckpoints/imgreconstruct2021_100000.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo2bsxMDazQW"
      },
      "source": [
        "## predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NqYaT_AQN4q"
      },
      "source": [
        "now that the model is trained it can be used to make prediction: this for us mean to crete high resolution image versions of low resolution imputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcklN-01M8vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b5667b-907e-4551-e03c-9a3942258dc3"
      },
      "source": [
        "outim = model.predict(X_te)\n",
        "# the output if a high res image for each image in input\n",
        "outim.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72, 4900)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPwVppg1Qa0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99109051-2d6f-4334-938b-251a88389b4b"
      },
      "source": [
        "# to be read as images the predictions have to be organized in pizel rows and columns\n",
        "outim[0].reshape(imgs_orig[0].shape).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 70, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROEqgG3aM8yV"
      },
      "source": [
        "import scipy\n",
        "def compareinout(i, outim, X_te):\n",
        "  '''function to plot the input, the prediction and the target in 3 columns\n",
        "  plots the ith training datum'''\n",
        "  fig = pl.figure(figsize(10,5))\n",
        "  ax = fig.add_subplot(131) \n",
        "  ax.imshow(X_te[i].reshape(imgs[i].shape[:2]) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = fig.add_subplot(132) \n",
        "  ax.imshow(outim[i].reshape(imgs_orig[i].shape[:2]) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  ax = fig.add_subplot(133) \n",
        "  ax.imshow(y_te[i].reshape(imgs_orig[i].shape[:2]) , cmap=\"bone\")\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  print(\"similarity {:.2f}\".format(scipy.stats.entropy(outim[i], y_te[i])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL4c1HGBqdkJ"
      },
      "source": [
        "plot some input-outpu pairs and the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsCU__LQM8sZ"
      },
      "source": [
        "np.random.seed(123)\n",
        "# pick a few random test images\n",
        "for i in range(30):\n",
        "  j = np.random.randint(0, len(X_te))\n",
        "  print(i + 1, \":\\tinput\\t\\t   prediction\\t\\ttarget\")\n",
        "  compareinout(j, outim, X_te)\n",
        "  pl.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HIViBLyFT35"
      },
      "source": [
        "What do you think? some are pretty good right?! e.g. 1, 4, 6, 7, 8\n",
        "\n",
        "Some are really bad. 9... why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uublY5EI0Pg"
      },
      "source": [
        "inspet the imput data: for each of 72 persons in the dataset there are 20 images. inspect one per person"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mng81vRIyTA"
      },
      "source": [
        "#folders = glob.glob(\"faces95/*\")\n",
        "axs = pl.figure(figsize=(15,15)).subplots(9,8)\n",
        "\n",
        "for i,f in enumerate(folders):\n",
        "  #im = Image.open(f + \"/1.jpg\")\n",
        "  np_im = numpy.array(imgs_orig[i*20].reshape(imgs_orig[0].shape[:-1])) \n",
        "  axs[i//8][i%8].imshow(np_im, cmap='bone')\n",
        "  axs[i//8][i%8].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk9UpMzNCQxc"
      },
      "source": [
        "# test the model on your own image\n",
        " depending on the initial size you will have to downsample the image, and extract a single color layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toNdpUXXXp22"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqjGUx1X9GQ"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtnzijr4aKiq"
      },
      "source": [
        "imme = Image.open(YOUR IMAGE NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nomjmQYWYEsp"
      },
      "source": [
        "numpy.array(imme).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01oQXI3wYJLI"
      },
      "source": [
        "pl.imshow(numpy.array(imme))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg2DMQjofqm8"
      },
      "source": [
        "**figure out how to shape it to make it the right number of pixels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCB2vJT3aCZz"
      },
      "source": [
        "Nsamp = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "labuDyU9YaXo"
      },
      "source": [
        "testimage = numpy.array(imme)[:Nsamp*35,450:Nsamp*35+450, :3].mean(axis=-1)\n",
        "pl.imshow(testimage, cmap=\"bone\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaKMsyRVY1AS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebc234f-e27c-4db9-ecb8-8d7f4aff1ec9"
      },
      "source": [
        "print(35*Nsamp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MbDdOuzCtp3"
      },
      "source": [
        "low resolution version\n",
        "subsampling by 25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJUeeG3jxRkR"
      },
      "source": [
        "pl.imshow(testimage[::Nsamp,::Nsamp], cmap=\"bone\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1BP4EUSzl8F"
      },
      "source": [
        "pl.imshow(model.predict(np.array([testimage[::Nsamp,::Nsamp].flatten() * 1.0 / \n",
        "                                  testimage[::Nsamp,::Nsamp].max()])).reshape(70,70), \n",
        "          cmap=\"bone\")\n",
        "pl.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn22HV8EJrD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}